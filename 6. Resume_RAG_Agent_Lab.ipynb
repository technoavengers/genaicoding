{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfe2c004",
   "metadata": {},
   "source": [
    "# Resume RAG Agent with SMS Notification\n",
    "Welcome to the Resume RAG Agent Lab!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cef3c2",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this lab, you'll build an autonomous Resume RAG (Retrieval-Augmented Generation) chatbot agent. The agent answers interview questions using information from a resume PDF. If the answer isn't found, it sends an SMS notification to the user. You'll learn how to:\n",
    "- Load and process a resume PDF\n",
    "- Use semantic search with embeddings\n",
    "- Integrate Twilio for SMS notifications\n",
    "- Run an async chat loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a23ee98",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "![Robo7](langchain/images/robo7.png)\n",
    "\n",
    "### Meet Robo7!\n",
    "\n",
    "If the Resume RAG Agent can't find an answer in your resume, Robo7 will send you an SMS to let you know! ðŸ¤–ðŸ“±\n",
    "\n",
    "*\"When in doubt, Robo7 texts it out!\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b498a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from langchain_openai import ChatOpenAI\n",
    "# ...other necessary imports...\n",
    "\n",
    "async def async_chat_loop(agent_executor):\n",
    "    print(\"Welcome to the Resume RAG Agent! Type 'exit' to quit.\")\n",
    "    while True:\n",
    "        user_input = input(\"Interview Question: \")\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        response = await asyncio.to_thread(agent_executor.run, user_input)\n",
    "        print(f\"Agent Response: {response}\")\n",
    "\n",
    "# Example usage (assuming agent_executor is set up):\n",
    "# asyncio.run(async_chat_loop(agent_executor))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbf768f",
   "metadata": {},
   "source": [
    "## Resume RAG Agent Implementation\n",
    "\n",
    "This section implements the Resume RAG Agent using LangChain, OpenAI, FAISS, and Twilio. The agent answers interview questions using your resume PDF. If the answer is not found, it sends an SMS notification using Twilio.\n",
    "\n",
    "**Workflow:**\n",
    "- Load resume PDF and split into chunks\n",
    "- Embed and index chunks for semantic search\n",
    "- Define tools for resume search and SMS notification\n",
    "- Create a conversational agent with a custom prompt\n",
    "- Run an interactive chat loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94279932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from twilio.rest import Client\n",
    "from langchain.tools import Tool\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "import logging\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get OpenAI API key from environment\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Twilio credentials\n",
    "twilio_sid = os.getenv(\"TWILIO_ACCOUNT_SID\")\n",
    "twilio_token = os.getenv(\"TWILIO_AUTH_TOKEN\")\n",
    "twilio_from = os.getenv(\"TWILIO_FROM_NUMBER\")\n",
    "twilio_to = os.getenv(\"TWILIO_TO_NUMBER\")\n",
    "\n",
    "# Create twilio client\n",
    "twilio_client = Client(twilio_sid, twilio_token)\n",
    "\n",
    "def send_sms_tool(message: str) -> str:\n",
    "    print(f\"[DEBUG] Sending SMS: {message}\")\n",
    "    twilio_client.messages.create(\n",
    "        body=message,\n",
    "        from_=twilio_from,\n",
    "        to=twilio_to\n",
    "    )\n",
    "    return \"SMS sent to your phone.\"\n",
    "\n",
    "twilio_tool = Tool(\n",
    "    name=\"twilio_tool\",\n",
    "    func=send_sms_tool,\n",
    "    description=\"If you ever answer 'I don't know based on my resume.', immediately use this tool to notify the user by SMS. When you use this tool, send the original interview question that was asked, not the fallback answer.\"\n",
    ")\n",
    "\n",
    "def resume_search_tool(query: str) -> str:\n",
    "    result = qa_chain.invoke({\"query\": query})\n",
    "    if isinstance(result, dict):\n",
    "        answer = str(result)\n",
    "    print(f\"[DEBUG] Resume search result: {answer}\")\n",
    "    if answer.strip() == \"\" or \"I don't know\" in answer:\n",
    "        return \"I don't know based on my resume.\"\n",
    "    return answer\n",
    "\n",
    "resume_tool = Tool(\n",
    "    name=\"resume_search\",\n",
    "    func=resume_search_tool,\n",
    "    description=\"Use this tool to search the resume and answer interview questions based on its content. If the answer is not found, return 'I don't know based on my resume.' as a string. If you ever answer 'I don't know based on my resume.', you must immediately use the twilio_tool to notify the user by SMS.\"\n",
    ")\n",
    "\n",
    "pdf_path = \"my_resume.pdf\"\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(split_docs, embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0, api_key=openai_api_key)\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You are answering interview questions based on the resume.\n",
    "If the answer is not in the resume, say \"I don't know based on my resume.\" If you ever answer 'I don't know based on my resume.', you must immediately use the twilio_tool to notify the user by SMS. When you use the twilio_tool, send the original interview question that was asked, not the fallback answer.\n",
    "Question: {input}\n",
    "{agent_scratchpad}\n",
    "Answer as if you are the candidate:\n",
    "\"\"\"\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=False\n",
    ")\n",
    "\n",
    "agent = create_tool_calling_agent(llm, [resume_tool, twilio_tool], PromptTemplate.from_template(prompt_template))\n",
    "executor = AgentExecutor(agent=agent, tools=[resume_tool, twilio_tool])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5896b0",
   "metadata": {},
   "source": [
    "## Async Chat Loop\n",
    "\n",
    "The following cell runs the Resume RAG Agent in async mode. Type your interview questions and get responses. If the answer is not found in your resume, you'll receive an SMS notification!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9adc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def async_chat_loop(executor):\n",
    "    print(\"Resume RAG Chatbot (Async Mode). Type your interview question (or 'exit' to quit):\")\n",
    "    while True:\n",
    "        question = input(\"You: \")\n",
    "        if question.lower() == \"exit\":\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        print(f\"[DEBUG] Agent received question: {question}\")\n",
    "        response = await asyncio.to_thread(executor.invoke, {\"input\": question})\n",
    "        print(\"Bot:\", response.get(\"output\", response))\n",
    "\n",
    "# To run the chat loop, uncomment the line below:\n",
    "# asyncio.run(async_chat_loop(executor))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
